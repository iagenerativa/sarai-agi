"""
Benchmark for expanded TRM templates (v3.7.0).

Tests accuracy with 51 templates across 6 categories.

Target: 95%+ accuracy on closed simple queries
Current: 15 templates â†’ 84.2% accuracy (benchmark_trm.py)
Expected: 51 templates â†’ 95%+ accuracy

Version: v3.7.0
Date: 2025-11-05
Author: SARAi Development Team
"""

import sys
sys.path.insert(0, 'src')

from sarai_agi.trm.template_manager import TemplateResponseManager
import time


def run_accuracy_benchmark():
    """Test TRM accuracy with comprehensive test set."""
    
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print("ðŸŽ¯ TRM ACCURACY BENCHMARK (Expanded Templates)")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    trm = TemplateResponseManager(lang='es')
    
    # Comprehensive test set covering all categories + variations
    test_cases = {
        # GREETINGS (15 variations)
        'hola': True,
        'buenos dÃ­as': True,
        'buenas tardes': True,
        'buenas noches': True,
        'hey': True,
        'quÃ© tal': True,
        'quÃ© onda': True,
        'buenas': True,
        'hola de nuevo': True,
        'cÃ³mo va todo': True,
        'me alegro de verte': True,
        'encantado': True,
        'saludos': True,
        'buen dÃ­a': True,
        'quÃ© pasa': True,
        
        # CONFIRMATIONS (15 variations)
        'sÃ­': True,
        'no': True,
        'vale': True,
        'ok': True,
        'claro': True,
        'correcto': True,
        'entiendo': True,
        'de acuerdo': True,
        'puede ser': True,
        'estÃ¡ bien': True,
        'eso mismo': True,
        'afirmativo': True,
        'exacto': True,
        'obvio': True,
        'dale': True,
        
        # THANKS (10 variations)
        'gracias': True,
        'muchas gracias': True,
        'te lo agradezco': True,
        'perfecto gracias': True,
        'eso es todo gracias': True,
        'aprecio tu ayuda': True,
        'gracias por todo': True,
        'muy amable': True,
        'mil gracias': True,
        'valoro tu ayuda': True,
        
        # FAREWELLS (12 variations)
        'adiÃ³s': True,
        'chau': True,
        'hasta luego': True,
        'nos vemos': True,
        'hasta pronto': True,
        'me voy': True,
        'bye': True,
        'buenas noches adiÃ³s': True,
        'hasta aquÃ­': True,
        'nos vemos luego': True,
        'cuÃ­date': True,
        'hasta maÃ±ana': True,
        
        # HELP (10 variations)
        'ayuda': True,
        'quÃ© puedes hacer': True,
        'cÃ³mo funciona': True,
        'instrucciones': True,
        'no entiendo': True,
        'quiÃ©n eres': True,
        'ejemplos': True,
        'cÃ³mo te llamas': True,
        'quÃ© sabes hacer': True,
        'necesito ayuda': True,
        
        # STATUS (12 variations)
        'estÃ¡s ahÃ­': True,
        'me escuchas': True,
        'funciona': True,
        'cÃ³mo estÃ¡s': True,
        'listo': True,
        'ocupado': True,
        'prueba': True,
        'puedes responder': True,
        'sigues ahÃ­': True,
        'me oyes': True,
        'estÃ¡s funcionando': True,
        'estÃ¡s disponible': True,
        
        # NEGATIVE CASES (should NOT match - complex queries)
        'explÃ­came la relatividad': False,
        'cuÃ¡nto es 2 + 2': False,
        'busca informaciÃ³n sobre python': False,
        'traduce hello al espaÃ±ol': False,
        'cuÃ¡l es la capital de Francia': False,
        'quÃ© tiempo hace hoy': False,
        'resuelve esta ecuaciÃ³n': False,
        'genera cÃ³digo python': False,
    }
    
    print(f"\nðŸ“Š Testing {len(test_cases)} queries...")
    print(f"   â”œâ”€ Expected matches (closed simple): {sum(test_cases.values())}")
    print(f"   â””â”€ Expected no-match (complex): {len(test_cases) - sum(test_cases.values())}\n")
    
    correct = 0
    total = len(test_cases)
    
    category_stats = {}
    latencies = []
    
    for query, should_match in test_cases.items():
        start = time.perf_counter()
        result = trm.match(query)
        latency_ms = (time.perf_counter() - start) * 1000
        latencies.append(latency_ms)
        
        matched = result is not None
        is_correct = matched == should_match
        
        if is_correct:
            correct += 1
        
        # Track by category
        if matched and result:
            cat = result.get('category', 'unknown')
            if cat not in category_stats:
                category_stats[cat] = {'correct': 0, 'total': 0}
            category_stats[cat]['total'] += 1
            if is_correct:
                category_stats[cat]['correct'] += 1
        
        # Show failures
        if not is_correct:
            expected = "MATCH" if should_match else "NO MATCH"
            actual = "MATCH" if matched else "NO MATCH"
            print(f"   âŒ FAIL: \"{query}\" (expected {expected}, got {actual})")
    
    accuracy = (correct / total) * 100
    
    print("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print("ðŸ“Š RESULTS:")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"   Total queries:        {total}")
    print(f"   Correct:              {correct}")
    print(f"   Accuracy:             {accuracy:.1f}%")
    print(f"   Target:               95.0%")
    print(f"   Status:               {'âœ… PASS' if accuracy >= 95.0 else 'âš ï¸ NEEDS IMPROVEMENT'}")
    
    print("\nðŸ“‹ Category Breakdown:")
    for cat in sorted(category_stats.keys()):
        stats = category_stats[cat]
        cat_acc = (stats['correct'] / stats['total']) * 100 if stats['total'] > 0 else 0
        print(f"   {cat:15s}: {stats['correct']:2d}/{stats['total']:2d} ({cat_acc:5.1f}%)")
    
    print(f"\nâš¡ Performance:")
    print(f"   Avg latency:          {sum(latencies)/len(latencies):.4f}ms")
    print(f"   P50 latency:          {sorted(latencies)[len(latencies)//2]:.4f}ms")
    print(f"   P95 latency:          {sorted(latencies)[int(len(latencies)*0.95)]:.4f}ms")
    print(f"   P99 latency:          {sorted(latencies)[int(len(latencies)*0.99)]:.4f}ms")
    print(f"   Max latency:          {max(latencies):.4f}ms")
    print(f"   Target:               <50ms")
    print(f"   Status:               {'âœ… PASS' if max(latencies) < 50 else 'âŒ FAIL'}")
    
    print("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    return accuracy >= 95.0


if __name__ == '__main__':
    success = run_accuracy_benchmark()
    sys.exit(0 if success else 1)
