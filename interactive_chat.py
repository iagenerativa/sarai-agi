#!/usr/bin/env python3
"""
Interactive Chat con SARAi - AnÃ¡lisis de Performance en Tiempo Real

Permite conversaciÃ³n natural con SARAi midiendo:
- Latencia de cada componente
- Cuellos de botella
- Uso de recursos
- MÃ©tricas de calidad

Usage:
    python3 interactive_chat.py
"""

import sys
sys.path.insert(0, 'src')

import time
import asyncio
from dataclasses import dataclass, field
from typing import Optional, List, Dict
from collections import deque
import psutil
import os

# SARAi Components
from sarai_agi.trm.template_manager import TemplateResponseManager
from sarai_agi.routing.unknown_handler import UnknownHandler

# TTS Engine - Piper (10x mÃ¡s rÃ¡pido que MeloTTS)
try:
    from sarai_agi.audio.pipertts import PiperTTSAdapter as TTSEngine
    TTS_ENGINE_NAME = "Piper TTS"
except ImportError:
    print("âš ï¸  Piper TTS no disponible, usando MeloTTS como fallback")
    from sarai_agi.audio.melotts import MeloTTS as TTSEngine
    TTS_ENGINE_NAME = "MeloTTS (fallback)"


@dataclass
class PerformanceMetrics:
    """MÃ©tricas de performance de una respuesta."""
    query: str
    total_time: float = 0.0
    
    # Component timings
    trm_time: float = 0.0
    unknown_check_time: float = 0.0
    response_gen_time: float = 0.0
    tts_time: float = 0.0
    
    # Resource usage
    ram_before_mb: float = 0.0
    ram_after_mb: float = 0.0
    ram_delta_mb: float = 0.0
    
    # Response info
    response_text: str = ""
    response_length: int = 0
    audio_duration: float = 0.0
    audio_samples: int = 0
    
    # Classification
    is_template: bool = False
    is_unknown: bool = False
    route_taken: str = ""
    
    def get_bottleneck(self) -> str:
        """Identifica el cuello de botella principal."""
        timings = {
            'TRM': self.trm_time,
            'Unknown Check': self.unknown_check_time,
            'Response Gen': self.response_gen_time,
            'TTS': self.tts_time
        }
        
        max_component = max(timings.items(), key=lambda x: x[1])
        return f"{max_component[0]} ({max_component[1]:.3f}s)"
    
    def get_summary(self) -> str:
        """Resumen de mÃ©tricas."""
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ MÃ‰TRICAS DE PERFORMANCE                                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Query: {self.query[:70]:<70} â•‘
â•‘ Route: {self.route_taken:<70} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ TIMINGS (ms):                                                                â•‘
â•‘   â€¢ TRM Classification:    {self.trm_time*1000:>8.2f} ms                                  â•‘
â•‘   â€¢ Unknown Detection:     {self.unknown_check_time*1000:>8.2f} ms                                  â•‘
â•‘   â€¢ Response Generation:   {self.response_gen_time*1000:>8.2f} ms                                  â•‘
â•‘   â€¢ TTS Synthesis:         {self.tts_time*1000:>8.2f} ms                                  â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘   â€¢ TOTAL:                 {self.total_time*1000:>8.2f} ms                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ BOTTLENECK: {self.get_bottleneck():<65} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ RECURSOS:                                                                    â•‘
â•‘   â€¢ RAM Delta:             {self.ram_delta_mb:>8.2f} MB                                  â•‘
â•‘   â€¢ Response Length:       {self.response_length:>8} chars                               â•‘
â•‘   â€¢ Audio Duration:        {self.audio_duration:>8.2f} s                                    â•‘
â•‘   â€¢ Audio Samples:         {self.audio_samples:>8} samples                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""


@dataclass
class SessionStats:
    """EstadÃ­sticas acumuladas de la sesiÃ³n."""
    queries: List[PerformanceMetrics] = field(default_factory=list)
    start_time: float = field(default_factory=time.time)
    
    def add_query(self, metrics: PerformanceMetrics):
        """Agrega mÃ©tricas de una query."""
        self.queries.append(metrics)
    
    def get_avg_timing(self, component: str) -> float:
        """Obtiene tiempo promedio de un componente."""
        if not self.queries:
            return 0.0
        
        timings = {
            'trm': [q.trm_time for q in self.queries],
            'unknown': [q.unknown_check_time for q in self.queries],
            'response': [q.response_gen_time for q in self.queries],
            'tts': [q.tts_time for q in self.queries],
            'total': [q.total_time for q in self.queries]
        }
        
        return sum(timings.get(component, [])) / len(self.queries) if self.queries else 0.0
    
    def get_bottleneck_summary(self) -> Dict[str, int]:
        """Cuenta cuÃ¡ntas veces cada componente fue el cuello de botella."""
        bottlenecks = {}
        for q in self.queries:
            component = q.get_bottleneck().split(' ')[0]
            bottlenecks[component] = bottlenecks.get(component, 0) + 1
        return bottlenecks
    
    def get_summary(self) -> str:
        """Resumen de la sesiÃ³n completa."""
        if not self.queries:
            return "No hay queries registradas."
        
        session_duration = time.time() - self.start_time
        bottlenecks = self.get_bottleneck_summary()
        
        template_count = sum(1 for q in self.queries if q.is_template)
        unknown_count = sum(1 for q in self.queries if q.is_unknown)
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ RESUMEN DE SESIÃ“N                                                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ DuraciÃ³n: {session_duration:>8.2f} segundos                                            â•‘
â•‘ Queries:  {len(self.queries):>8} totales                                                 â•‘
â•‘   â€¢ Templates:  {template_count:>5}                                                      â•‘
â•‘   â€¢ Unknown:    {unknown_count:>5}                                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ TIEMPOS PROMEDIO (ms):                                                       â•‘
â•‘   â€¢ TRM:              {self.get_avg_timing('trm')*1000:>8.2f} ms                                  â•‘
â•‘   â€¢ Unknown Check:    {self.get_avg_timing('unknown')*1000:>8.2f} ms                                  â•‘
â•‘   â€¢ Response Gen:     {self.get_avg_timing('response')*1000:>8.2f} ms                                  â•‘
â•‘   â€¢ TTS:              {self.get_avg_timing('tts')*1000:>8.2f} ms                                  â•‘
â•‘   â€¢ TOTAL:            {self.get_avg_timing('total')*1000:>8.2f} ms                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ CUELLOS DE BOTELLA (frecuencia):                                            â•‘
"""
        
        for component, count in sorted(bottlenecks.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(self.queries)) * 100
            summary += f"â•‘   â€¢ {component:<15} {count:>3} veces ({percentage:>5.1f}%)                           â•‘\n"
        
        summary += "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        return summary


class InteractiveSARAi:
    """Chat interactivo con SARAi con mediciÃ³n de performance."""
    
    def __init__(self, enable_tts: bool = True):
        """
        Inicializa el sistema interactivo.
        
        Args:
            enable_tts: Si True, genera audio (mÃ¡s lento). Si False, solo texto.
        """
        print("ğŸš€ Inicializando SARAi Interactive Chat...")
        print("=" * 80)
        
        # Components
        self.trm = TemplateResponseManager()
        self.unknown_handler = UnknownHandler()
        self.tts = TTSEngine() if enable_tts else None
        self.enable_tts = enable_tts and (self.tts is not None)
        
        # Stats
        self.session_stats = SessionStats()
        
        # Info
        print(f"âœ… TTS Engine: {TTS_ENGINE_NAME}")
        
        # Process info
        self.process = psutil.Process(os.getpid())
        
        print(f"âœ… TRM: {self.trm} cargado")
        print(f"âœ… Unknown Handler: Activo")
        print(f"{'âœ…' if self.enable_tts else 'âš ï¸ '} TTS: {'Habilitado' if self.enable_tts else 'Deshabilitado (modo texto)'}")
        print("=" * 80)
    
    def get_ram_usage_mb(self) -> float:
        """Obtiene uso de RAM en MB."""
        return self.process.memory_info().rss / 1024 / 1024
    
    def process_query(self, query: str, verbose: bool = True) -> PerformanceMetrics:
        """
        Procesa una query y mide performance.
        
        Args:
            query: Query del usuario
            verbose: Si True, muestra detalles en consola
            
        Returns:
            MÃ©tricas de performance
        """
        metrics = PerformanceMetrics(query=query)
        start_total = time.time()
        metrics.ram_before_mb = self.get_ram_usage_mb()
        
        # 1. TRM Classification
        start = time.time()
        template_result = self.trm.match(query)
        metrics.trm_time = time.time() - start
        metrics.is_template = template_result is not None
        
        if verbose:
            print(f"\nâ±ï¸  TRM: {metrics.trm_time*1000:.2f}ms â†’ {'âœ“ Template' if metrics.is_template else 'âœ— No template'}")
        
        # 2. Unknown Detection
        start = time.time()
        unknown_result = self.unknown_handler.detect(query)
        metrics.unknown_check_time = time.time() - start
        metrics.is_unknown = unknown_result.is_unknown if hasattr(unknown_result, 'is_unknown') else False
        
        if verbose:
            print(f"â±ï¸  Unknown: {metrics.unknown_check_time*1000:.2f}ms â†’ {'âš ï¸  Unknown' if metrics.is_unknown else 'âœ“ Known'}")
        
        # 3. Response Generation
        start = time.time()
        
        if metrics.is_template:
            response = template_result.get('response', template_result.get('text', 'Template response'))
            metrics.route_taken = f"Template ({template_result.get('category', 'unknown')})"
        elif metrics.is_unknown:
            response = "Lo siento, no puedo ayudarte con eso por razones de privacidad."
            metrics.route_taken = "Unknown (Privacy)"
        else:
            # AquÃ­ irÃ­a el modelo LLM real
            response = f"Respuesta simulada para: {query}"
            metrics.route_taken = "LLM (Simulated)"
        
        metrics.response_gen_time = time.time() - start
        metrics.response_text = response
        metrics.response_length = len(response)
        
        if verbose:
            print(f"â±ï¸  Response: {metrics.response_gen_time*1000:.2f}ms â†’ {len(response)} chars")
            print(f"ğŸ’¬ Respuesta: {response}")
        
        # 4. TTS Synthesis (opcional)
        if self.enable_tts:
            start = time.time()
            audio = self.tts.synthesize(response, speaker="ES", speed=1.0)
            metrics.tts_time = time.time() - start
            
            if audio is not None:
                metrics.audio_samples = len(audio)
                metrics.audio_duration = len(audio) / self.tts.get_sample_rate()
                
                if verbose:
                    print(f"â±ï¸  TTS: {metrics.tts_time*1000:.2f}ms â†’ {metrics.audio_duration:.2f}s audio")
            else:
                if verbose:
                    print(f"âš ï¸  TTS: FallÃ³ la sÃ­ntesis")
        else:
            if verbose:
                print(f"â­ï¸  TTS: Deshabilitado")
        
        # Final metrics
        metrics.total_time = time.time() - start_total
        metrics.ram_after_mb = self.get_ram_usage_mb()
        metrics.ram_delta_mb = metrics.ram_after_mb - metrics.ram_before_mb
        
        if verbose:
            print(f"\nâ±ï¸  TOTAL: {metrics.total_time*1000:.2f}ms")
            print(f"ğŸ§  RAM: {metrics.ram_delta_mb:+.2f}MB (now {metrics.ram_after_mb:.1f}MB)")
        
        return metrics
    
    def run(self):
        """Ejecuta el chat interactivo."""
        print("\n" + "=" * 80)
        print("ğŸ¯ SARAi Interactive Chat - AnÃ¡lisis de Performance")
        print("=" * 80)
        print("\nComandos:")
        print("  â€¢ Escribe tu mensaje para chatear")
        print("  â€¢ 'stats' - Ver estadÃ­sticas de la sesiÃ³n")
        print("  â€¢ 'clear' - Limpiar estadÃ­sticas")
        print("  â€¢ 'tts on/off' - Habilitar/deshabilitar audio")
        print("  â€¢ 'quit' / 'exit' / 'q' - Salir")
        print("\n" + "=" * 80)
        
        query_count = 0
        
        while True:
            try:
                # Input
                query = input(f"\nğŸ§‘ TÃº [{query_count}]: ").strip()
                
                if not query:
                    continue
                
                # Commands
                if query.lower() in ['quit', 'exit', 'q']:
                    print("\nğŸ‘‹ Â¡Hasta luego!")
                    break
                
                if query.lower() == 'stats':
                    print(self.session_stats.get_summary())
                    continue
                
                if query.lower() == 'clear':
                    self.session_stats = SessionStats()
                    query_count = 0
                    print("âœ… EstadÃ­sticas limpiadas")
                    continue
                
                if query.lower() == 'tts on':
                    if self.tts and self.tts.is_available():
                        self.enable_tts = True
                        print("âœ… TTS habilitado")
                    else:
                        print("âš ï¸  TTS no disponible")
                    continue
                
                if query.lower() == 'tts off':
                    self.enable_tts = False
                    print("âœ… TTS deshabilitado")
                    continue
                
                # Process query
                print("\n" + "-" * 80)
                print(f"âš™ï¸  Procesando...")
                
                metrics = self.process_query(query, verbose=True)
                self.session_stats.add_query(metrics)
                query_count += 1
                
                # Show bottleneck
                print(f"\nğŸ” Cuello de botella: {metrics.get_bottleneck()}")
                print("-" * 80)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ SesiÃ³n interrumpida")
                break
            except Exception as e:
                print(f"\nâŒ Error: {e}")
                import traceback
                traceback.print_exc()
        
        # Final summary
        if self.session_stats.queries:
            print("\n" + "=" * 80)
            print("ğŸ“Š RESUMEN FINAL DE LA SESIÃ“N")
            print("=" * 80)
            print(self.session_stats.get_summary())


def main():
    """Entry point."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Interactive chat con SARAi')
    parser.add_argument('--no-tts', action='store_true', help='Deshabilitar TTS (mÃ¡s rÃ¡pido)')
    parser.add_argument('--benchmark', type=str, help='Ejecutar benchmark con queries de archivo')
    
    args = parser.parse_args()
    
    if args.benchmark:
        # Benchmark mode
        print(f"ğŸ“Š Modo Benchmark: {args.benchmark}")
        chat = InteractiveSARAi(enable_tts=not args.no_tts)
        
        with open(args.benchmark, 'r') as f:
            queries = [line.strip() for line in f if line.strip()]
        
        print(f"Ejecutando {len(queries)} queries...")
        
        for i, query in enumerate(queries, 1):
            print(f"\n{'='*80}\nQuery {i}/{len(queries)}: {query}")
            metrics = chat.process_query(query, verbose=True)
            chat.session_stats.add_query(metrics)
        
        print(chat.session_stats.get_summary())
    else:
        # Interactive mode
        chat = InteractiveSARAi(enable_tts=not args.no_tts)
        chat.run()


if __name__ == '__main__':
    main()
