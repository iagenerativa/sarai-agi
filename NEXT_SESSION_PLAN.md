# PrÃ³xima SesiÃ³n - Plan de Trabajo

**Fecha**: 6 Nov 2025  
**SesiÃ³n**: Week 2 Day 6-7  
**Objetivo**: Qdrant Vector DB - Sistema de Memoria SemÃ¡ntica

---

## âœ… Estado Actual (5 Nov 2025)

### Week 1 COMPLETADA 100% ğŸ‰
- âœ… Day 1-2: STT + VAD + Audio Utils (1,420 LOC)
- âœ… Day 3-4: MeloTTS + Expresividad (730 LOC)
- âœ… Day 5: Fillers System (730 LOC)
- **Total**: 2,880 LOC + 31 tests
- **Status**: Production-ready âœ…

---

## ğŸ“‹ NEXT SESSION PLAN - SARAi v3.8.0

**Fecha**: 6 Nov 2025  
**Contexto**: Week 1 COMPLETADO (2,880 LOC, 29/31 tests passing)  
**PrÃ³ximo objetivo**: TTS Streaming Queue OPTIMIZADO + Week 2 start

---

## ğŸ¯ PRIORIDAD 1: TTS Streaming Queue con Overlap Prediction (7h) â­ **ACTUALIZADO**

### MotivaciÃ³n (User Request)
**"Se puede optimizar incluso el proceso, sabiendo cuanto tarda en procesar el texto a voz y cuanto dura la frase que se estÃ¡ reproduciendo con el fin de ir concatenando las frases de una manera natural, sin que el interlocutor note pausas y mejorando los tiempo de procesamiento globales"**

### Problema Actual
- Respuestas largas tienen 10-20s latencia inicial (blocking synthesis)
- Streaming simple tiene gaps 0.2s entre frases (notable)
- No hay gestiÃ³n de prioridades (interrupciones lentas)
- No prediction de overlaps (sÃ­ntesis serial)

### SoluciÃ³n Optimizada
1. **Predictive Overlap**: Calcula duraciÃ³n audio vs tiempo sÃ­ntesis
2. **EWMA Learning**: Aprende timing real de sÃ­ntesis
3. **Zero-Gap Playback**: Empieza sÃ­ntesis siguiente ANTES de terminar actual
4. **Priority Queues**: HIGH/NORMAL/LOW con preemption
5. **LoRA Scheduler**: Predice interrupciones, optimiza queue depth

### ImplementaciÃ³n - 5 Fases

#### FASE 1: Core Streaming (2h)
**Archivos**:
- `src/sarai_agi/audio/sentence_splitter.py` (50 LOC)
  - Regex-based splitting
  - Handle Spanish punctuation (Â¿?Â¡!)
  - Edge cases: abreviaturas (Dr., Sr.), nÃºmeros (3.14)
  - Tests: 10 test cases
  
- `src/sarai_agi/audio/tts_queue.py` (200 LOC) â­
  - TTSQueue class con overlap prediction
  - EWMA timing (avg_synthesis_time con Î±=0.3)
  - Producer thread: synthesize con timing measurement
  - Consumer thread: playback con gap measurement
  - Overlap calculation: `wait_time = audio_duration - synthesis_time - margin`
  - Methods: synthesize_streaming(), stop(), get_metrics()
  
- `src/sarai_agi/audio/melotts.py` (+50 LOC)
  - New method: synthesize_streaming(text, on_chunk, **kwargs)
  - Returns metrics dict (synthesis_times, gaps, total_time)
  - Backward compatible (keep existing methods)
  
**Tests**: `tests/test_tts_streaming.py` (150 LOC, 8 tests)
- Test sentence splitting
- Test queue operations
- Test overlap prediction accuracy
- Test gap measurement (<0.05s target)
- Test EWMA convergence
- Test interrupt handling
- Test metrics reporting

**Deliverable**: Streaming TTS funcional con CERO gaps âœ…

---

#### FASE 2: OptimizaciÃ³n Performance (1.5h)
**Archivos**:
- `tests/test_tts_performance.py` (100 LOC, 4 tests)
  - Benchmark latency to first audio (<2s)
  - Benchmark gap promedio (<0.05s)
  - Stress test (50+ frases, estabilidad)
  - Memory leak test (100 iterations)
  
**Tuning**:
- Ajustar `prefetch_margin` (0.3-0.7s testing)
- Ajustar EWMA alpha (0.2-0.4 testing)
- Ajustar queue maxsize (2-4 testing)
- Validar convergencia EWMA (<5 samples)

**Deliverable**: Performance validado, mÃ©tricas documentadas âœ…

---

#### FASE 3: Priority Queue System (1h) â­
**Archivos**:
- `src/sarai_agi/audio/priority_tts_queue.py` (150 LOC)
  - PriorityTTSQueue class
  - 3 niveles: HIGH (interrupts), NORMAL (responses), LOW (fillers)
  - Preemptive interruption: HIGH can stop NORMAL/LOW
  - Starvation prevention: LOW max wait 30s
  - Methods: enqueue(text, priority), interrupt(), get_queue_stats()

**Tests**: `tests/test_priority_queue.py` (120 LOC, 6 tests)
- Test HIGH priority preemption
- Test interrupt latency (<100ms)
- Test starvation prevention
- Test queue ordering
- Test multi-priority concurrent

**Deliverable**: Sistema de prioridades robusto âœ…

---

#### FASE 4: LoRA Scheduler Integration (1.5h) â­
**Archivos**:
- `src/sarai_agi/audio/lora_scheduler.py` (100 LOC)
  - LoRAScheduler class
  - predict_interrupt_probability(sentence, context)
  - update_from_feedback(interrupted, context)
  - Adaptive queue depth based on prediction
  - Re-train every 50 samples
  
- `src/sarai_agi/audio/scheduler_integration.py` (50 LOC)
  - Integration PriorityQueue + LoRAScheduler
  - Auto-adjust priorities based on predictions
  - Feedback loop: track actual interrupts

**Tests**: `tests/test_lora_scheduler.py` (80 LOC, 4 tests)
- Test prediction accuracy (>70% target)
- Test feedback loop convergence
- Test adaptive queue depth
- Test edge cases (no training data)

**Deliverable**: Sistema adaptativo que aprende de usuario âœ…

---

#### FASE 5: Demo ConversaciÃ³n Real (1h) â­ **CRÃTICO UX**
**Archivos**:
- `examples/interactive_conversation_test.py` (250 LOC)
  - MicrÃ³fono en vivo (Vosk STT)
  - VAD para detectar silencio (Sherpa)
  - Processing pipeline (STT â†’ LLM â†’ TTS streaming)
  - VisualizaciÃ³n en tiempo real:
    * MÃ©tricas: latency, gaps, synthesis time
    * Progress bar: frase actual / total
    * Gap indicator: visual de pausas
  - 5 test scenarios implementados:
    1. Consulta corta (1 frase)
    2. ExplicaciÃ³n media (3-5 frases)
    3. Respuesta larga (10+ frases)
    4. InterrupciÃ³n usuario
    5. Multi-turn conversation
  
**Output Esperado**:
```
ğŸ¤ USER: "ExplÃ­came la teorÃ­a de la relatividad"
â±ï¸  Pipeline: STT=0.8s | LLM=1.2s | TTS_START=2.0s

ğŸ”Š SARAI [1/8]: "La teorÃ­a de la relatividad fue propuesta por Einstein."
   ğŸ“Š Synthesis: 2.1s | Audio: 3.2s | Gap: 0.00s âœ…
   
ğŸ”Š SARAI [2/8]: "Consta de dos partes principales."
   ğŸ“Š Synthesis: 1.9s | Audio: 2.8s | Gap: 0.01s âœ…
   
... (continÃºa fluidamente)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ˆ FINAL METRICS:
   Total sentences: 8
   Avg synthesis time: 2.04s (EWMA converged âœ…)
   Avg gap: 0.012s (TARGET: <0.05s âœ…)
   Latency (first audio): 2.0s (TARGET: <2s âœ…)
   Total time: 28.3s
   vs Blocking: 45s â†’ -37% improvement âœ…
   
ğŸ’¯ USER EXPERIENCE: FLUENT & NATURAL âœ¨
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**Deliverable**: Demo completo para validaciÃ³n UX maÃ±ana âœ…

---

### Resumen TTS Streaming

**Total Estimado**: 7 horas
- FASE 1 Core: 2h
- FASE 2 Performance: 1.5h
- FASE 3 Priorities: 1h
- FASE 4 LoRA: 1.5h
- FASE 5 Demo: 1h

**LOC Total**: ~650 LOC
- sentence_splitter.py: 50
- tts_queue.py: 200 (con overlap)
- priority_tts_queue.py: 150
- lora_scheduler.py: 100
- melotts.py updates: 50
- interactive demo: 250

**Tests**: 22 tests
- Core streaming: 8
- Performance: 4
- Priority queue: 6
- LoRA scheduler: 4

**Benefits**:
- âœ… Latencia percibida: -90% (20s â†’ 2s)
- âœ… Gaps entre frases: 0.0s (zero pausas)
- âœ… Flujo natural: Como humano hablando
- âœ… Interrupciones: <100ms response
- âœ… Adaptive: Aprende de usuario con LoRA
- âœ… Production-ready: Demo validado

---

## ğŸ“… PRIORIDAD 2: Week 2 Day 6-7 - Qdrant Vector DB (4-5h)

**DESPUÃ‰S** de TTS Streaming Optimizado (7h)  
**Tiempo restante Day 6**: ~1-2h (si dÃ­a completo 8h)  
**Day 7 completo**: 8h  
**Total disponible**: 9-10h para Qdrant + preparaciÃ³n LoRA

---

### Qdrant Vector DB Implementation

**Objetivo**: Sistema de memoria semÃ¡ntica para contexto a largo plazo

**Componentes a Implementar**:

1. **qdrant_client.py** (~200 LOC)
   - Cliente Qdrant local/cloud
   - Vector store management
   - Collection management
   - STRICT MODE graceful degradation

2. **embeddings.py** (~150 LOC)
   - EmbeddingGemma-300M integration
   - Text â†’ Vector conversion
   - Batch processing
   - Cache de embeddings

3. **semantic_search.py** (~100 LOC)
   - Query processing
   - Similarity search
   - Context retrieval
   - Result ranking

4. **Tests** (10-12 tests)
   - Qdrant connection
   - Vector operations
   - Semantic search
   - Edge cases

**Features**:
- âœ… Semantic search en conversaciones pasadas
- âœ… Context retrieval para respuestas coherentes
- âœ… Long-term memory persistente
- âœ… Vector similarity search
- âœ… Automatic embedding generation

**Estimado**: 6-8 horas

---

## ğŸ“‹ Checklist Day 6-7

### âš¡ PRIORIDAD: TTS Streaming (2-3 horas)
- [ ] Implementar sentence_splitter.py
- [ ] Implementar tts_queue.py
- [ ] Update melotts.py con streaming mode
- [ ] Tests streaming (8-10 tests)
- [ ] Demo streaming vs blocking

### Setup Qdrant (30 min)
- [ ] Instalar qdrant-client
- [ ] Setup Qdrant local (Docker o in-memory)
- [ ] Verificar EmbeddingGemma disponible
- [ ] Crear estructura de directorios

### ImplementaciÃ³n (4-5 horas)
- [ ] qdrant_client.py (conexiÃ³n + CRUD)
- [ ] embeddings.py (generaciÃ³n + cache)
- [ ] semantic_search.py (bÃºsqueda + ranking)
- [ ] Integration con pipeline existente

### Tests (1-2 horas)
- [ ] Test connection + collections
- [ ] Test vector operations
- [ ] Test semantic search
- [ ] Test edge cases
- [ ] Target: 10-12 tests passing

### DocumentaciÃ³n (1 hora)
- [ ] WEEK2_DAY6-7_RESUMEN.md
- [ ] Code documentation (docstrings)
- [ ] Usage examples
- [ ] Integration guide

---

## ğŸ”§ Dependencias Necesarias

```bash
# Qdrant
pip install qdrant-client==1.7.0

# Embeddings (si no estÃ¡)
# EmbeddingGemma-300M ya disponible en models/cache/
```

---

## ğŸ“š Referencias

- **Qdrant Docs**: https://qdrant.tech/documentation/
- **Python Client**: https://github.com/qdrant/qdrant-client
- **EmbeddingGemma**: Ya integrado en v3.7.0

---

## ğŸš€ Roadmap Completo Week 2

- **Day 6**: TTS Streaming Queue (2-3h) â† CRÃTICO
- **Day 6-7**: Qdrant Vector DB (4-5h)
- **Day 8-9**: LoRA Optimizer (6-8h)
- **Day 10-11**: TRM Supervised Learning (6-8h)
- **Day 12**: Integration Testing (4h)

**Total Week 2**: ~24-28 horas estimadas

---

## ğŸ’¡ Notas Importantes

1. **TTS Streaming es CRÃTICO** para buena UX - implementar primero
2. **Sentence-level mejor que word-level** (balance latencia/calidad)
3. **Queue thread-safe** necesaria para concurrencia
4. **Qdrant puede correr local** (sin cloud) para desarrollo
5. **EmbeddingGemma ya estÃ¡ disponible** (300M parÃ¡metros)
6. **Integration con audio pipeline** serÃ¡ automÃ¡tica
7. **Vector DB serÃ¡ base** para RAG avanzado en Week 3

---

**Ãšltima actualizaciÃ³n**: 5 Nov 2025, 23:50  
**Preparado por**: SARAi AGI Team  
**Estado**: Ready to start Week 2 ğŸš€
